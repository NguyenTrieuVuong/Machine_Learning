{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGd2NnLBsBL0",
        "outputId": "2fe5dd32-a333-401c-d4a7-6c42f9e774fc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/gdrive/Shareddrives/data_face_HUS/data_face_HUS.zip -d \"/content/\""
      ],
      "metadata": {
        "id": "1ek_tsXBsW7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e8b7a83-ade9-4eb3-a3b0-7f2b9347630d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/gdrive/Shareddrives/data_face_HUS/data_face_HUS.zip\n",
            "replace /content/data_face_HUS/Nguyen_Manh_Trung_20002171/a6.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KSdxOBUzM5Zp",
        "outputId": "e72fed56-cb94-4c04-d47c-25d0f9be5947"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VeXKzLw6EERn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "folder_path = 'data_face_HUS/*/*'\n",
        "\n",
        "# Find all files in subfolders\n",
        "files = glob.glob(folder_path, recursive=True)\n",
        "\n",
        "# Categorize files based on subfolder name\n",
        "categories = {}\n",
        "\n",
        "for file in files:\n",
        "    subfolder = os.path.basename(os.path.dirname(file))\n",
        "    if subfolder in categories:\n",
        "        categories[subfolder].append(file)\n",
        "    else:\n",
        "        categories[subfolder] = [file]\n",
        "\n",
        "X_train_label = []\n",
        "X_train_list = []\n",
        "X_test_label = []\n",
        "X_test_list = []\n",
        "for category, files in categories.items():\n",
        "    # print(category)\n",
        "    # for file in files:\n",
        "    #     print('\\t', file)\n",
        "    train_list = glob.glob('data_face_HUS/'+category+'/*')\n",
        "    for name in train_list:\n",
        "        img = cv2.imread(name)\n",
        "        if img is not None:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            img = cv2.resize(img,(64,64))\n",
        "            X_train_list.append(img)\n",
        "            X_train_label.append(category)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/gdrive/Shareddrives/data_face_HUS/facenet_keras.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "DIxfuE8QN8co",
        "outputId": "14645785-ca57-4a57-f02b-4166d0149c9b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d8e56f5de13b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/Shareddrives/data_face_HUS/facenet_keras.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mfunc_load\u001b[0;34m(code, defaults, closure, globs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mUnicodeEncodeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinascii\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mraw_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw_unicode_escape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarshal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mglobs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mglobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: bad marshal data (unknown type code)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train_list)\n",
        "y_train = np.array(X_train_label)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "iAmzfCIfBoeY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "inp = Input(shape=(28,28,1))\n",
        "x = Conv2D(filters = 8, kernel_size = 3, activation = 'relu')(inp)\n",
        "x = MaxPooling2D(pool_size = (2,2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(units = 32, activation = 'relu')(x)\n",
        "x = Dense(units = 2)(x)\n",
        "\n",
        "cnn = Model(inputs = inp, outputs = x)\n",
        "img1 = Input(shape = (28,28,1))\n",
        "img2 = Input(shape = (28,28,1))\n",
        "\n",
        "f1 = cnn(img1)\n",
        "f2 = cnn(img2)\n",
        "\n",
        "d = K.sqrt(K.sum(K.square(f1 - f2),axis = 1, keepdims = True))\n",
        "\n",
        "model = Model(inputs = [img1,img2], outputs = d)\n",
        "model.summary()\n",
        "cnn.summary()\n",
        "\n",
        "def loss(y_true, y_pred):\n",
        "  proba = K.exp(-K.square(y_pred))\n",
        "  return -K.mean(y_true * K.log(proba) + (1-y_true) * K.log(1-proba))\n",
        "\n",
        "def loss1(y_true, y_pred):\n",
        "  return K.mean(y_true * K.square(y_pred) + (1-y_true) * K.square(K.maximum(1.0 - y_pred, 0)))\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = loss1)"
      ],
      "metadata": {
        "id": "tmvjV9A9EwcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def generator(X,y,k = 8):\n",
        "  unique_labels = np.unique(y)\n",
        "\n",
        "  while True:\n",
        "    X1 = []\n",
        "    X2 = []\n",
        "    y_batch = []\n",
        "    for label in unique_labels:\n",
        "      label_idx = np.where(y == label)[0]\n",
        "      other_labels = set(unique_labels) - {label}\n",
        "\n",
        "      for i in range(k):\n",
        "        i1 = np.random.choice(label_idx)\n",
        "        i2 = np.random.choice(label_idx)\n",
        "        # i1 must be different from i2\n",
        "        while i1 == i2:\n",
        "          i2 = np.random.choice(label_idx)\n",
        "        # create positive example\n",
        "        X1.append(X[i1][:,:,None])\n",
        "        X2.append(X[i2][:,:,None])\n",
        "        y_batch.append(1.0)\n",
        "\n",
        "        # create negative example\n",
        "        i1 = np.random.choice(label_idx)\n",
        "        my_label = np.random.choice(list(other_labels))\n",
        "        i2 = np.random.choice(list(np.where(y == my_label)[0]))\n",
        "        X1.append(X[i1][:,:,None])\n",
        "        X2.append(X[i2][:,:,None])\n",
        "        y_batch.append(0.0)\n",
        "    yield [np.array(X1) / 255., np.array(X2) / 255.], np.array(y_batch)\n",
        "\n",
        "# For testing\n",
        "for pair, y in generator(X_test, y_test):\n",
        "  print('Batch size: ', len(y))\n",
        "  idx = np.random.choice(range(len(y)))\n",
        "  print(pair[0][idx].shape)\n",
        "  print('Pair label:', y[idx])\n",
        "  plt.subplot(121)\n",
        "  plt.imshow(pair[0][idx].reshape(28,28), cmap = 'gray')\n",
        "  plt.subplot(122)\n",
        "  plt.imshow(pair[1][idx].reshape(28,28), cmap = 'gray')\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "id": "soStx1FWHZuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(generator(X_train, y_train, k = 32),\n",
        "                    steps_per_epoch = 5,\n",
        "                    epochs = 500,\n",
        "                    validation_data = generator(X_test, y_test, k = 8),\n",
        "                    validation_steps = 5)"
      ],
      "metadata": {
        "id": "1HBX7T9mKTIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label = 'Train', c = 'b')\n",
        "plt.plot(history.history['val_loss'], label = 'Validation', c = 'r')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch', fontsize = 16)\n",
        "plt.ylabel('Loss', fontsize = 16)"
      ],
      "metadata": {
        "id": "Gt5_T1jsOU7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for pair, y in generator(X_test, y_test):\n",
        "  y_pred = model.predict(pair)\n",
        "  print('Batch_size: ', len(y))\n",
        "  idx = np.random.choice(range(len(y)))\n",
        "  print('Pair label:', y[idx])\n",
        "  print('Distance:', y_pred[idx])\n",
        "\n",
        "  f1 = cnn(pair[0])\n",
        "  f2 = cnn(pair[1])\n",
        "  d = np.sqrt(np.sum((f1-f2)**2,axis = 1, keepdims = True))\n",
        "  print('Distance by features:', d[idx])\n",
        "\n",
        "  plt.subplot(121)\n",
        "  plt.imshow(pair[0][idx].reshape(28,28),cmap = 'gray')\n",
        "  plt.subplot(122)\n",
        "  plt.imshow(pair[1][idx].reshape(28,28),cmap = 'gray')\n",
        "  break"
      ],
      "metadata": {
        "id": "LPHbthSaOzpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = cnn.predict(X_test/255.)\n",
        "p = plt.scatter(f[:,0],f[:,1], c = y_test, s=1)\n",
        "plt.colorbar(p)"
      ],
      "metadata": {
        "id": "rvlhpW2rRRMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.save('cnn_loss1.h5')"
      ],
      "metadata": {
        "id": "d1z8ySVNRoyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "m = load_model('cnn_loss1.h5')\n",
        "\n",
        "f1 = m.predict(X_test / 255.)\n",
        "p = plt.scatter(f1[:,0],f1[:,1],c=y_test,s=1)\n",
        "plt.colorbar(p)"
      ],
      "metadata": {
        "id": "ixWPqfncRsVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for pair,y in generator(X_test,y_test):\n",
        "  f1 = cnn(pair[0])\n",
        "  f2 = cnn(pair[1])\n",
        "  d = np.sqrt(np.sum((f1 - f2)**2, axis = 1, keepdims = True))\n",
        "  y_pred +=list(d.ravel())\n",
        "  y_true +=list(y)\n",
        "  i+=1\n",
        "  if i>500:\n",
        "    break"
      ],
      "metadata": {
        "id": "Ve9TX8IUStM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.array(y_pred)\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "positive_distances = y_pred[y_true == 1]\n",
        "negative_distances = y_pred[y_true == 0]\n",
        "\n",
        "plt.hist(positive_distances, color = 'r', density = True, bins = 20)\n",
        "plt.hist(negative_distances, color = 'b', density = True, bins = 20)"
      ],
      "metadata": {
        "id": "Bme_3CCdTTmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thresh = 0.5\n",
        "y_pred_ = y_pred < thresh\n",
        "y_pred_.astype('uint8')\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_pred_))"
      ],
      "metadata": {
        "id": "p-c-GOHBTvq1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}